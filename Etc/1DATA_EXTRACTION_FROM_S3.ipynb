{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb147cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cbfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client =boto3.client('s3')\n",
    "s3_bucket_name='hackathon2023'\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id= 'AKIA3AEXDSNEGXQERCGG',\n",
    "                    aws_secret_access_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c57bf4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket.objectsCollection(s3.Bucket(name='hackathon2023'), s3.ObjectSummary)\n",
      "4\n",
      "['data/OperationsManagement/PlansShiftWise/PlansShiftWise.csv', 'data/OperationsManagement/Results/Results.csv', 'data/OperationsManagement/Workorders/Workorders.csv', 'data/SCSupplyChain/warehouse/warehouse.csv']\n"
     ]
    }
   ],
   "source": [
    "my_bucket=s3.Bucket(s3_bucket_name)\n",
    "print(my_bucket.objects.filter(Prefix='data'))\n",
    "bucket_list = []\n",
    "for file in my_bucket.objects.filter(Prefix = 'data'):\n",
    "    \n",
    "    file_name=file.key\n",
    "    if file_name.find(\".csv\")!=-1:\n",
    "        bucket_list.append(file.key)\n",
    "length_bucket_list=print(len(bucket_list))\n",
    "print(bucket_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca0d1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info[0] < 3:\n",
    "    from StringIO import StringIO  # Python 2.x\n",
    "else:\n",
    "    from io import StringIO  # Python 3.x\n",
    "    \n",
    "df = []   # Initializing empty list of dataframes\n",
    "for file in bucket_list:\n",
    "    obj = s3.Object(s3_bucket_name,file)\n",
    "    data=obj.get()['Body'].read()\n",
    "    df.append(pd.read_csv(io.BytesIO(data), header=0, low_memory=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "366e321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "018fe3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>W-749816B-8722848856_20</th>\n",
       "      <th>W-749816B-8722848856</th>\n",
       "      <th>W-749816</th>\n",
       "      <th>W-749816B-8722848856.1</th>\n",
       "      <th>W-749816B-8722848856.2</th>\n",
       "      <th>EEAgent</th>\n",
       "      <th>0.1</th>\n",
       "      <th>2022-06-01 17:02:00</th>\n",
       "      <th>...</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>EE-0001</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>W-749816B-71801103384_13</td>\n",
       "      <td>W-749816B-71801103384</td>\n",
       "      <td>W-749816</td>\n",
       "      <td>W-749816B-71801103384</td>\n",
       "      <td>W-749816B-71801103384</td>\n",
       "      <td>EEAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 17:12:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EE-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>W-749816B-48685952117_22</td>\n",
       "      <td>W-749816B-48685952117</td>\n",
       "      <td>W-749816</td>\n",
       "      <td>W-749816B-48685952117</td>\n",
       "      <td>W-749816B-48685952117</td>\n",
       "      <td>EEAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 17:22:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EE-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>W-749816B-25850813917_23</td>\n",
       "      <td>W-749816B-25850813917</td>\n",
       "      <td>W-749816</td>\n",
       "      <td>W-749816B-25850813917</td>\n",
       "      <td>W-749816B-25850813917</td>\n",
       "      <td>EEAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 17:32:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EE-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>W-749816B-5596928600_29</td>\n",
       "      <td>W-749816B-5596928600</td>\n",
       "      <td>W-749816</td>\n",
       "      <td>W-749816B-5596928600</td>\n",
       "      <td>W-749816B-5596928600</td>\n",
       "      <td>EEAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 17:42:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EE-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>W-749816B-56458449767_16</td>\n",
       "      <td>W-749816B-56458449767</td>\n",
       "      <td>W-749816</td>\n",
       "      <td>W-749816B-56458449767</td>\n",
       "      <td>W-749816B-56458449767</td>\n",
       "      <td>EEAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 17:52:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EE-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77136</th>\n",
       "      <td>77138</td>\n",
       "      <td>0</td>\n",
       "      <td>W-989803B-34904579707_27</td>\n",
       "      <td>W-989803B-34904579707</td>\n",
       "      <td>W-989803</td>\n",
       "      <td>W-989803B-34904579707</td>\n",
       "      <td>W-989803B-34904579707</td>\n",
       "      <td>EPAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-10 06:32:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EP-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77137</th>\n",
       "      <td>77139</td>\n",
       "      <td>0</td>\n",
       "      <td>W-989803B-89923620898_17</td>\n",
       "      <td>W-989803B-89923620898</td>\n",
       "      <td>W-989803</td>\n",
       "      <td>W-989803B-89923620898</td>\n",
       "      <td>W-989803B-89923620898</td>\n",
       "      <td>EPAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-10 06:42:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EP-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77138</th>\n",
       "      <td>77140</td>\n",
       "      <td>0</td>\n",
       "      <td>W-989803B-91771370800_16</td>\n",
       "      <td>W-989803B-91771370800</td>\n",
       "      <td>W-989803</td>\n",
       "      <td>W-989803B-91771370800</td>\n",
       "      <td>W-989803B-91771370800</td>\n",
       "      <td>EPAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-10 06:52:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EP-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77139</th>\n",
       "      <td>77141</td>\n",
       "      <td>0</td>\n",
       "      <td>W-989803B-58782909661_29</td>\n",
       "      <td>W-989803B-58782909661</td>\n",
       "      <td>W-989803</td>\n",
       "      <td>W-989803B-58782909661</td>\n",
       "      <td>W-989803B-58782909661</td>\n",
       "      <td>EPAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-10 07:02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EP-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77140</th>\n",
       "      <td>77142</td>\n",
       "      <td>0</td>\n",
       "      <td>W-989803B-28992178339_14</td>\n",
       "      <td>W-989803B-28992178339</td>\n",
       "      <td>W-989803</td>\n",
       "      <td>W-989803B-28992178339</td>\n",
       "      <td>W-989803B-28992178339</td>\n",
       "      <td>EPAgent</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-10 07:12:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EP-0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77141 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1  0   W-749816B-8722848856_20   W-749816B-8722848856  W-749816  \\\n",
       "0          2  0  W-749816B-71801103384_13  W-749816B-71801103384  W-749816   \n",
       "1          3  0  W-749816B-48685952117_22  W-749816B-48685952117  W-749816   \n",
       "2          4  0  W-749816B-25850813917_23  W-749816B-25850813917  W-749816   \n",
       "3          5  0   W-749816B-5596928600_29   W-749816B-5596928600  W-749816   \n",
       "4          6  0  W-749816B-56458449767_16  W-749816B-56458449767  W-749816   \n",
       "...      ... ..                       ...                    ...       ...   \n",
       "77136  77138  0  W-989803B-34904579707_27  W-989803B-34904579707  W-989803   \n",
       "77137  77139  0  W-989803B-89923620898_17  W-989803B-89923620898  W-989803   \n",
       "77138  77140  0  W-989803B-91771370800_16  W-989803B-91771370800  W-989803   \n",
       "77139  77141  0  W-989803B-58782909661_29  W-989803B-58782909661  W-989803   \n",
       "77140  77142  0  W-989803B-28992178339_14  W-989803B-28992178339  W-989803   \n",
       "\n",
       "      W-749816B-8722848856.1 W-749816B-8722848856.2  EEAgent  0.1  \\\n",
       "0      W-749816B-71801103384  W-749816B-71801103384  EEAgent    0   \n",
       "1      W-749816B-48685952117  W-749816B-48685952117  EEAgent    0   \n",
       "2      W-749816B-25850813917  W-749816B-25850813917  EEAgent    0   \n",
       "3       W-749816B-5596928600   W-749816B-5596928600  EEAgent    0   \n",
       "4      W-749816B-56458449767  W-749816B-56458449767  EEAgent    0   \n",
       "...                      ...                    ...      ...  ...   \n",
       "77136  W-989803B-34904579707  W-989803B-34904579707  EPAgent    0   \n",
       "77137  W-989803B-89923620898  W-989803B-89923620898  EPAgent    0   \n",
       "77138  W-989803B-91771370800  W-989803B-91771370800  EPAgent    0   \n",
       "77139  W-989803B-58782909661  W-989803B-58782909661  EPAgent    0   \n",
       "77140  W-989803B-28992178339  W-989803B-28992178339  EPAgent    0   \n",
       "\n",
       "       2022-06-01 17:02:00  ... 0.3  0.4  EE-0001  Unnamed: 16  Unnamed: 17  \\\n",
       "0      2022-06-01 17:12:00  ...   0    0  EE-0001          NaN          NaN   \n",
       "1      2022-06-01 17:22:00  ...   0    0  EE-0001          NaN          NaN   \n",
       "2      2022-06-01 17:32:00  ...   0    0  EE-0001          NaN          NaN   \n",
       "3      2022-06-01 17:42:00  ...   0    0  EE-0001          NaN          NaN   \n",
       "4      2022-06-01 17:52:00  ...   0    0  EE-0001          NaN          NaN   \n",
       "...                    ...  ...  ..  ...      ...          ...          ...   \n",
       "77136  2022-06-10 06:32:00  ...   0    0  EP-0001          NaN          NaN   \n",
       "77137  2022-06-10 06:42:00  ...   0    0  EP-0001          NaN          NaN   \n",
       "77138  2022-06-10 06:52:00  ...   0    0  EP-0001          NaN          NaN   \n",
       "77139  2022-06-10 07:02:00  ...   0    0  EP-0001          NaN          NaN   \n",
       "77140  2022-06-10 07:12:00  ...   0    0  EP-0001          NaN          NaN   \n",
       "\n",
       "      Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  \n",
       "0             NaN          NaN          NaN          NaN          NaN  \n",
       "1             NaN          NaN          NaN          NaN          NaN  \n",
       "2             NaN          NaN          NaN          NaN          NaN  \n",
       "3             NaN          NaN          NaN          NaN          NaN  \n",
       "4             NaN          NaN          NaN          NaN          NaN  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "77136         NaN          NaN          NaN          NaN          NaN  \n",
       "77137         NaN          NaN          NaN          NaN          NaN  \n",
       "77138         NaN          NaN          NaN          NaN          NaN  \n",
       "77139         NaN          NaN          NaN          NaN          NaN  \n",
       "77140         NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[77141 rows x 23 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7840ccff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [101]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m mainarr\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID|ItemNo|Date|Shift|Station|Hour|Quantity|LineLeader|Bay|DivisionId|CreationDateTime|BreakTime|WorkOrderId|Company|Division\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 18\u001b[0m  x \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m  arr\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     20\u001b[0m  \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(x)):\n",
      "\u001b[1;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "#lst = []\n",
    "#clean_df = pd.DataFrame(lst,columns=['ID','ItemNo','Date','Shift','Station','Hour','Quantity','LineLeader','Bay','DivisionId','CreationDateTime','BreakTime','WorkOrderId','Company','Division'])\n",
    "#print(clean_df)\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "#data = []\n",
    "#columns=['ID','ItemNo','Date','Shift','Station','Hour','Quantity','LineLeader','Bay','DivisionId','CreationDateTime','BreakTime','WorkOrderId','Company','Division']\n",
    "#clean_df=spark.createDataFrame(data=data, schema = columns)\n",
    "#clean_df.show()\n",
    "mainarr=[]\n",
    "for i in df[0]['ID|ItemNo|Date|Shift|Station|Hour|Quantity|LineLeader|Bay|DivisionId|CreationDateTime|BreakTime|WorkOrderId|Company|Division']:\n",
    "\n",
    " x = i.split(\"\")\n",
    " arr=[]\n",
    " for i in range (0,len(x)):\n",
    "    if(x[i]==\"\"):\n",
    "        x[i]=\"0\"\n",
    "    #print(x[i])\n",
    "    arr.append(x[i])\n",
    " mainarr.append(tuple(arr))\n",
    "\n",
    "\n",
    " columns=['ID','ItemNo','Date','Shift','Station','Hour','Quantity','LineLeader','Bay','DivisionId','CreationDateTime','BreakTime','WorkOrderId','Company','Division']\n",
    "df_clean=pd.DataFrame(mainarr,columns=columns)\n",
    "\n",
    "df_clean\n",
    "#print(mainarr)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38054674",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_df = pd.DataFrame(columns=['ID','ItemNo','Date','Shift','Station','Hour','Quantity','LineLeader','Bay','DivisionId','CreationDateTime','BreakTime','WorkOrderId','Company','Division'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b04f7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[1;32m----> 4\u001b[0m     converted_df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data \u001b[38;5;241m=\u001b[39m file)\n\u001b[0;32m      5\u001b[0m     converted_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mconcatenate([converted_df\u001b[38;5;241m.\u001b[39mvalues, converted_df1\u001b[38;5;241m.\u001b[39mvalues]), columns\u001b[38;5;241m=\u001b[39mconverted_df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:756\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# For data is scalar\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 756\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame constructor not properly called!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;66;03m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[39;00m\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;66;03m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[39;00m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;66;03m# Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[0;32m    761\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for file in df[0]:\n",
    "    \n",
    "    converted_df1 = pd.DataFrame(data = file)\n",
    "    converted_df = pd.DataFrame(np.concatenate([converted_df.values, converted_df1.values]), columns=converted_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de0bfdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\serializers.py\", line 458, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 602, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 692, in reducer_override\n",
      "    return self._function_reduce(obj)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 565, in _function_reduce\n",
      "    return self._dynamic_function_reduce(obj)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 546, in _dynamic_function_reduce\n",
      "    state = _function_getstate(func)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py\", line 157, in _function_getstate\n",
      "    f_globals_ref = _extract_code_globals(func.__code__)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 334, in _extract_code_globals\n",
      "    out_names = {names[oparg]: None for _, oparg in _walk_global_ops(co)}\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 334, in <dictcomp>\n",
      "    out_names = {names[oparg]: None for _, oparg in _walk_global_ops(co)}\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py\", line 523, in _walk_global_ops\n",
      "    for instr in dis.get_instructions(code):\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dis.py\", line 321, in _get_instructions_bytes\n",
      "    labels = findlabels(code)\n",
      "  File \"C:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dis.py\", line 441, in findlabels\n",
      "    for offset, op, arg in _unpack_opargs(code):\n",
      "TypeError: 'NoneType' object is not iterable\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: TypeError: 'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\serializers.py:458\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cloudpickle\u001b[38;5;241m.\u001b[39mdumps(obj, pickle_protocol)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[0;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m cp\u001b[38;5;241m.\u001b[39mdump(obj)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:602\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Pickler\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28mself\u001b[39m, obj)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:692\u001b[0m, in \u001b[0;36mCloudPickler.reducer_override\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_reduce(obj)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# fallback to save_global, including the Pickler's\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:565\u001b[0m, in \u001b[0;36mCloudPickler._function_reduce\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynamic_function_reduce(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:546\u001b[0m, in \u001b[0;36mCloudPickler._dynamic_function_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    545\u001b[0m newargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_getnewargs(func)\n\u001b[1;32m--> 546\u001b[0m state \u001b[38;5;241m=\u001b[39m _function_getstate(func)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (types\u001b[38;5;241m.\u001b[39mFunctionType, newargs, state, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    548\u001b[0m         _function_setstate)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle_fast.py:157\u001b[0m, in \u001b[0;36m_function_getstate\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    146\u001b[0m slotstate \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__qualname__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__closure__\u001b[39m\u001b[38;5;124m\"\u001b[39m: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__closure__\u001b[39m,\n\u001b[0;32m    155\u001b[0m }\n\u001b[1;32m--> 157\u001b[0m f_globals_ref \u001b[38;5;241m=\u001b[39m _extract_code_globals(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m)\n\u001b[0;32m    158\u001b[0m f_globals \u001b[38;5;241m=\u001b[39m {k: func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f_globals_ref \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    159\u001b[0m              func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:334\u001b[0m, in \u001b[0;36m_extract_code_globals\u001b[1;34m(co)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# We use a dict with None values instead of a set to get a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# deterministic order (assuming Python 3.6+) and avoid introducing\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# non-deterministic pickle bytes as a results.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m out_names \u001b[38;5;241m=\u001b[39m {names[oparg]: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _, oparg \u001b[38;5;129;01min\u001b[39;00m _walk_global_ops(co)}\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Declaring a function inside another one using the \"def ...\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# syntax generates a constant code object corresponding to the one\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# of the nested function's As the nested function may itself need\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# global variables, we need to introspect its code, extract its\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# globals, (look for code object in it's co_consts attribute..) and\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# add the result to code_globals\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:334\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# We use a dict with None values instead of a set to get a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# deterministic order (assuming Python 3.6+) and avoid introducing\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# non-deterministic pickle bytes as a results.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m out_names \u001b[38;5;241m=\u001b[39m {names[oparg]: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _, oparg \u001b[38;5;129;01min\u001b[39;00m _walk_global_ops(co)}\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Declaring a function inside another one using the \"def ...\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# syntax generates a constant code object corresponding to the one\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# of the nested function's As the nested function may itself need\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# global variables, we need to introspect its code, extract its\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# globals, (look for code object in it's co_consts attribute..) and\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# add the result to code_globals\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\cloudpickle\\cloudpickle.py:523\u001b[0m, in \u001b[0;36m_walk_global_ops\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03mYield (opcode, argument number) tuples for all\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03mglobal-referencing instructions in *code*.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instr \u001b[38;5;129;01min\u001b[39;00m dis\u001b[38;5;241m.\u001b[39mget_instructions(code):\n\u001b[0;32m    524\u001b[0m     op \u001b[38;5;241m=\u001b[39m instr\u001b[38;5;241m.\u001b[39mopcode\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dis.py:321\u001b[0m, in \u001b[0;36m_get_instructions_bytes\u001b[1;34m(code, varnames, names, constants, cells, linestarts, line_offset)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"Iterate over the instructions in a bytecode string.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03mGenerates a sequence of Instruction namedtuples giving the details of each\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m \n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m labels \u001b[38;5;241m=\u001b[39m findlabels(code)\n\u001b[0;32m    322\u001b[0m starts_line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dis.py:441\u001b[0m, in \u001b[0;36mfindlabels\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m    440\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m offset, op, arg \u001b[38;5;129;01min\u001b[39;00m _unpack_opargs(code):\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# creating a dataframe from the lists of data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(data, columns)\n\u001b[0;32m     22\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\session.py:894\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    892\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[0;32m    893\u001b[0m     )\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(\n\u001b[0;32m    895\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    896\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\session.py:938\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    936\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 938\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n\u001b[0;32m    939\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mapplySchemaToPythonRDD(jrdd\u001b[38;5;241m.\u001b[39mrdd(), struct\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m    940\u001b[0m df \u001b[38;5;241m=\u001b[39m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\rdd.py:3113\u001b[0m, in \u001b[0;36mRDD._to_java_object_rdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3110\u001b[0m rdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pickled()\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mpythonToJava(rdd\u001b[38;5;241m.\u001b[39m_jrdd, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\rdd.py:3505\u001b[0m, in \u001b[0;36mPipelinedRDD._jrdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3503\u001b[0m     profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3505\u001b[0m wrapped_func \u001b[38;5;241m=\u001b[39m _wrap_function(\n\u001b[0;32m   3506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_jrdd_deserializer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer, profiler\n\u001b[0;32m   3507\u001b[0m )\n\u001b[0;32m   3509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3510\u001b[0m python_rdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD(\n\u001b[0;32m   3511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_jrdd\u001b[38;5;241m.\u001b[39mrdd(), wrapped_func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreservesPartitioning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_barrier\n\u001b[0;32m   3512\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\rdd.py:3362\u001b[0m, in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m serializer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserializer should not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3361\u001b[0m command \u001b[38;5;241m=\u001b[39m (func, profiler, deserializer, serializer)\n\u001b[1;32m-> 3362\u001b[0m pickled_command, broadcast_vars, env, includes \u001b[38;5;241m=\u001b[39m _prepare_for_python_RDD(sc, command)\n\u001b[0;32m   3363\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonFunction(\n\u001b[0;32m   3365\u001b[0m     \u001b[38;5;28mbytearray\u001b[39m(pickled_command),\n\u001b[0;32m   3366\u001b[0m     env,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3371\u001b[0m     sc\u001b[38;5;241m.\u001b[39m_javaAccumulator,\n\u001b[0;32m   3372\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\rdd.py:3345\u001b[0m, in \u001b[0;36m_prepare_for_python_RDD\u001b[1;34m(sc, command)\u001b[0m\n\u001b[0;32m   3342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_python_RDD\u001b[39m(sc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkContext\u001b[39m\u001b[38;5;124m\"\u001b[39m, command: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, Any, Any, Any]:\n\u001b[0;32m   3343\u001b[0m     \u001b[38;5;66;03m# the serialized command will be compressed by broadcast\u001b[39;00m\n\u001b[0;32m   3344\u001b[0m     ser \u001b[38;5;241m=\u001b[39m CloudPickleSerializer()\n\u001b[1;32m-> 3345\u001b[0m     pickled_command \u001b[38;5;241m=\u001b[39m ser\u001b[38;5;241m.\u001b[39mdumps(command)\n\u001b[0;32m   3346\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pickled_command) \u001b[38;5;241m>\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetBroadcastThreshold(sc\u001b[38;5;241m.\u001b[39m_jsc):  \u001b[38;5;66;03m# Default 1M\u001b[39;00m\n\u001b[0;32m   3348\u001b[0m         \u001b[38;5;66;03m# The broadcast will have same life cycle as created PythonRDD\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\serializers.py:468\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    466\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not serialize object: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, emsg)\n\u001b[0;32m    467\u001b[0m print_exec(sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m--> 468\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPicklingError(msg)\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not serialize object: TypeError: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    " \n",
    "# importing sparksession from pyspark.sql module\n",
    "from pyspark.sql import SparkSession\n",
    " \n",
    "# creating sparksession and giving an app name\n",
    "spark = SparkSession.builder.appName('sparkdf').getOrCreate()\n",
    " \n",
    "# list  of employee data\n",
    "data = [[\"1\", \"sravan\", \"company 1\"],\n",
    "        [\"2\", \"ojaswi\", \"company 1\"],\n",
    "        [\"3\", \"rohith\", \"company 2\"],\n",
    "        [\"4\", \"sridevi\", \"company 1\"],\n",
    "        [\"5\", \"bobby\", \"company 1\"]]\n",
    " \n",
    "# specify column names\n",
    "columns = ['ID', 'NAME', 'Company']\n",
    " \n",
    "# creating a dataframe from the lists of data\n",
    "dataframe = spark.createDataFrame(data, columns)\n",
    " \n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc387ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "80f38e7ec0327a6414a55918c31a015cabb3c453423c70751535812149cec50d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
